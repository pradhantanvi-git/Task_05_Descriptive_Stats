# ğŸ“Œ Research Task 5 â€“ Descriptive Statistics & LLM Validation

## ğŸ“‚ Project Overview

This project analyzes **IPL 2022 cricket match data** using Python to answer both **basic** and **advanced research-oriented questions**.  
It also evaluates responses generated by **Large Language Models (LLMs)** such as **ChatGPT** and **Claude**, and validates their accuracy using Python scripts and descriptive statistics.

---

## ğŸ“¦ Attached Contents

- **ChatGPT_LLM_analysis.md** â€“ LLM-generated analysis of IPL 2022 dataset.
- **ChatPT_prompt.md** â€“ Prompt instructions given to the LLM.
- **ipl_2022_cricket_match_dataset.csv / .xlsx** â€“ Source dataset containing IPL 2022 match details.
- **script_validation.py** â€“ Python script for validating Q1â€“Q5.
- **Python script for CHAT GPT validation.py** â€“ Combined validator for advanced queries.
- **Chat GPT Error Analysis.md** â€“ Error analysis of ChatGPT responses.
- **Claude Error Analysis.md** â€“ Error analysis of Claude responses.
- **Claude supporting evidence screenshot.pdf** â€“ Screenshots of Claudeâ€™s responses.
- **GPT vs Claude Comparison.pdf** â€“ Comparison document for Chat GPT vs Claude LLM
- **readme.md** â€“ Documentation file (this file).

---

## ğŸ“ Research Questions Answered

### Basic (Q1â€“Q5)
1. Which team won the most matches?
2. Who was most often named Player of the Match?
3. How often did the toss winner also win the match?
4. For Gujarat Titans, how many wins came from chasing vs batting first?
5. Which 3 players had the highest individual scores in matches where they were awarded Player of the Match?

### Advanced (Q6â€“Q8)
6. Overall, did teams win more by defending or by chasing in IPL 2022?  
7. Which venues were most **batting-friendly** (highest average first-innings score) and most **chase-friendly** (highest % wins by wickets), considering only venues with at least 5 matches?  
8. Who handled **close games** the best? (define close = win by â‰¤10 runs or â‰¤3 wickets; only include teams with at least 3 such games)

---

## âš™ï¸ How to Run the Project

1. Ensure Python 3.x and pandas are installed on your system.
2. Place all attached files in the same working directory.
3. Open a terminal or command prompt and navigate to the folder containing the files.

For **basic Q1â€“Q5**:
```bash
python script_validation.py
```

For **advanced Q6â€“Q8**:
```bash
python Python script for CHAT GPT validation.py ipl_2022_cricket_match_dataset.csv
```

4. The console output will display each question (Q1â€“Q8) followed by its validated answer.  
5. CSV summaries will also be saved for advanced queries:
   - `venues_summary_min5.csv`  
   - `close_games_summary_min3.csv`  

---

## ğŸ” Notes

- The `ChatPT_prompt.md` file shows the exact instructions given to the LLMs.
- The `ChatGPT_LLM_analysis.md` file contains the LLM's responses for Q1â€“Q8.
- The Python scripts cross-verify the LLM answers using descriptive statistics from the dataset.
- Error analysis documents highlight where ChatGPT and Claude produced hallucinations or biased results.

---

## ğŸ“‰ LLM Error & Failure Analysis

- **Q5:** ChatGPT replaced Rajat Patidar (112) with KL Rahul (103*) â€” favoring a famous player.  
- **Q6:** Both GPT (40â€“34) and Claude (41â€“33) overstated chasing wins vs defending. Python showed exact balance (37â€“37).  
- **Q7:** GPT partially correct (Brabourne batting), Claude wrong on both. Python: Brabourne batting, Wankhede chase.  
- **Q8:** Both hallucinated Rajasthan/RCB close-game stats, ignoring Lucknow which tied with Gujarat.

---

## âœ… Key Research Takeaways

- **Narrative bias:** Both GPT & Claude leaned toward the *â€œchasing advantageâ€* storyline.  
- **Popularity bias:** Famous players/teams (KL Rahul, Rajasthan, RCB) were preferred over correct results (Patidar, Lucknow).  
- **Hallucination:** Both models produced believable but false stats.  
- **Narrative vs Data Gap:** Claude sometimes contradicted its own structured output.  
- **Validation critical:** Python scripts exposed errors that would otherwise go unnoticed.

---

## ğŸ“‘ Research Contribution

This project shows that **LLMs cannot yet be trusted for precise statistical reporting without external validation**.  
They generate **realistic but inaccurate narratives**, with biases toward popular players/teams.  
A **hybrid approach (LLM + Python)** is more reliable and highlights where LLMs fail.  
